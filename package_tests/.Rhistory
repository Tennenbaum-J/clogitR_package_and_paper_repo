mutate(sq_err = (beta_hat_T - beta_T)^2, rej = pval < 0.05) %>%
group_by(beta_T, true_funtion, regress_on_X, n, inference, X_style) %>%
summarize(
num_na = sum(is.na(pval)),
num_real = sum(!is.na(pval)),
mse = mean(sq_err, na.rm = TRUE),
percent_reject = sum(rej, na.rm = TRUE) / (n() - num_na),
mean_beta_hat_T = mean(beta_hat_T, na.rm = TRUE),
mean_sq_beta_hat_T = mean(sqrt(ssq_beta_hat_T), trim = 0.001, na.rm = TRUE),
.groups = "drop")
write.csv(res_mod, file = "C:/temp/clogitR_kap_test_from_scratch/combined_13000.csv", row.names = FALSE)
n=10000
beta_T = 1
y = array(NA, n)
probs = array(NA, n)
X = matrix(runif(n * 6, min = -1, max = 1), ncol = 6)
df = data.frame(cbind(id = 1:n, X))
df.dist = gendistance(data.frame(df[, -1]), idcol = 1)
df.mdm = distancematrix(df.dist)
df.match = nonbimatch(df.mdm)
T_inx = df.match$halves[,2]
C_ind = df.match$halves[,4]
X = X[c(rbind(T_inx, C_ind)), ] #zip them together, so the mathces should be 1,1,2,2,3,3...
w = c(rbind(replicate(n/2, sample(c(0, 1)), simplify = TRUE)))
strat = rep(1:(n/2), each = 2)
beta_X = c(3, 3, 3, 3, 3, 3)
beta_0 = -1
probs = 1 / (1 + exp(-(beta_0 + (as.matrix(X) %*% beta_X) + beta_T * w)))
y = rbinom(n, 1, probs)
ggplot(df, aes(x = probs, fill = factor(y))) +
geom_histogram(position = "identity", alpha = 0.6, bins = 30) +
labs(x = "Predicted probability", fill = "Outcome") +
scale_fill_manual(values = c("0" = "red", "1" = "blue")) +
theme_minimal()
T_inx = df.match$halves[,2]
C_ind = df.match$halves[,4]
X = X[c(rbind(T_inx, C_ind)), ] #zip them together, so the mathces should be 1,1,2,2,3,3...
w = c(rbind(replicate(n/2, sample(c(0, 1)), simplify = TRUE)))
strat = rep(1:(n/2), each = 2)
beta_X = c(3, 3, 3, 3, 3, 3)
beta_0 = -1
probs = 1 / (1 + exp(-(beta_0 + (as.matrix(X) %*% beta_X) + beta_T * w)))
y = rbinom(n, 1, probs)
ggplot(df, aes(x = probs, fill = factor(y))) +
geom_histogram(position = "identity", alpha = 0.6, bins = 30) +
labs(x = "Predicted probability", fill = "Outcome") +
scale_fill_manual(values = c("0" = "red", "1" = "blue")) +
theme_minimal()
f_x = sin(pi * X[, 1] * X[, 2]) + X[,3]^3 + X[, 4]^2 + X[, 5]^2
probs = 1 / (1 + exp(-(f_x + beta_T * w)))
if (true_funtion == "linear") {
beta_X = c(3, 3, 3, 3, 3, 3)
beta_0 = -1
probs = 1 / (1 + exp(-(beta_0 + (as.matrix(X) %*% beta_X) + beta_T * w)))
} else {
f_x = sin(pi * X[, 1] * X[, 2]) + X[,3]^3 + X[, 4]^2 + X[, 5]^2
probs = 1 / (1 + exp(-(f_x + beta_T * w)))
}
y = rbinom(n, 1, probs)
ggplot(df, aes(x = probs, fill = factor(y))) +
geom_histogram(position = "identity", alpha = 0.6, bins = 30) +
labs(x = "Predicted probability", fill = "Outcome") +
scale_fill_manual(values = c("0" = "red", "1" = "blue")) +
theme_minimal()
beta_X = c(2, 2, 2, 2, 2, 2)
beta_0 = -1
probs = 1 / (1 + exp(-(beta_0 + (as.matrix(X) %*% beta_X) + beta_T * w)))
y = rbinom(n, 1, probs)
ggplot(df, aes(x = probs, fill = factor(y))) +
geom_histogram(position = "identity", alpha = 0.6, bins = 30) +
labs(x = "Predicted probability", fill = "Outcome") +
scale_fill_manual(values = c("0" = "red", "1" = "blue")) +
theme_minimal()
beta_X = c(1, 1, 1, 1, 1, 1)
beta_0 = -1
probs = 1 / (1 + exp(-(beta_0 + (as.matrix(X) %*% beta_X) + beta_T * w)))
y = rbinom(n, 1, probs)
ggplot(df, aes(x = probs, fill = factor(y))) +
geom_histogram(position = "identity", alpha = 0.6, bins = 30) +
labs(x = "Predicted probability", fill = "Outcome") +
scale_fill_manual(values = c("0" = "red", "1" = "blue")) +
theme_minimal()
pacman::p_load(clogitR, dplyr, data.table, doFuture, future, doRNG, foreach, progressr, doParallel, nbpMatching, doParallel, ggplot2, geepack, glmmTMB) #doParallel
results = read.csv("C:/temp/clogitR_kap_test_from_scratch/1000_1.csv")
results = read.csv("C:/temp/clogitR_kap_test_from_scratch/1000_1.csv")
sum = 1
for (i in 2:475) {
file_path <- paste0("C:/temp/clogitR_kap_test_from_scratch/1000_", i, ".csv")
if (file.exists(file_path)) {
sum = sum +1
message("Reading file ", i)
temp <- read.csv(file_path)
results <- rbind(results, temp)
} else {
message("Skipping missing file ", i)
}
}
100 * (sum-1)
results$X = NULL
res_mod = results %>%
mutate(sq_err = (beta_hat_T - beta_T)^2, rej = pval < 0.05) %>%
group_by(beta_T, true_funtion, regress_on_X, n, inference, X_style) %>%
summarize(
num_na = sum(is.na(pval)),
num_real = sum(!is.na(pval)),
mse = mean(sq_err, na.rm = TRUE),
percent_reject = sum(rej, na.rm = TRUE) / (n() - num_na),
mean_beta_hat_T = mean(beta_hat_T, na.rm = TRUE),
mean_sq_beta_hat_T = mean(sqrt(ssq_beta_hat_T), trim = 0.001, na.rm = TRUE),
.groups = "drop")
write.csv(res_mod, file = "C:/temp/clogitR_kap_test_from_scratch/combined_17100.csv", row.names = FALSE)
pacman::p_load(ggplot2)
rm(list = ls())
n = 10000
d = 5/6
resolution = seq(from = 0, to = 1, by = 1/(100-1))
results = matrix(nrow = length(resolution), ncol = n)
for (r in 1:length(resolution)){
thresh = resolution[r]
player_A = runif(n)
player_B = runif(n)
for (i in 1:n) {
if (player_A[i] < 1/2) {
player_A[i] = runif(1)
}
if (player_A[i] < thresh) {
if (player_B[i] < thresh) {
player_B[i] = runif(1)
}
if (player_B[i] > player_A[i]) {
results[r, i] = 1
} else {
results[r, i] = 0
}
} else {
if (player_B[i] < thresh) {
player_B[i] = runif(1)
}
if (player_B[i] > player_A[i]) {
results[r, i] = 1
} else {
results[r, i] = 0
}
}
}
}
win_Chance = rowMeans(results)
df <- data.frame(
thresh = resolution,
win = win_Chance
)
ggplot(df, aes(x = thresh, y = win)) +
geom_line(linewidth = 1.2) +
ylim(0, 1) +
labs(
x = "Threshold",
y = "Win Chance",
title = "Player A Win Chance vs Threshold"
) +
theme_minimal()
pacman::p_load(ggplot2)
rm(list = ls())
n = 100000
d = 5/6
resolution = seq(from = 0, to = 1, by = 1/(1000-1))
results = matrix(nrow = length(resolution), ncol = n)
for (r in 1:length(resolution)){
thresh = resolution[r]
player_A = runif(n)
player_B = runif(n)
for (i in 1:n) {
if (player_A[i] < 1/2) {
player_A[i] = runif(1)
}
if (player_A[i] < thresh) {
if (player_B[i] < thresh) {
player_B[i] = runif(1)
}
if (player_B[i] > player_A[i]) {
results[r, i] = 1
} else {
results[r, i] = 0
}
} else {
if (player_B[i] < thresh) {
player_B[i] = runif(1)
}
if (player_B[i] > player_A[i]) {
results[r, i] = 1
} else {
results[r, i] = 0
}
}
}
}
win_Chance = rowMeans(results)
df <- data.frame(
thresh = resolution,
win = win_Chance
)
ggplot(df, aes(x = thresh, y = win)) +
geom_line(linewidth = 1.2) +
geom_vline(xintercept = 7/12, linetype = "dashed", linewidth = 1) +
ylim(0, 1) +
labs(
x = "Threshold",
y = "Win Chance",
title = "Player A Win Chance vs Threshold"
) +
theme_minimal()
win_Chance = rowMeans(results)
df <- data.frame(
thresh = resolution,
win = win_Chance,
theory = 1/4 + (7/8)*resolution - (3/4)*resolution^2
)
ggplot(df, aes(x = thresh)) +
geom_line(aes(y = win), linewidth = 1.2) +
geom_line(aes(y = theory), color = "red", linewidth = 1.2) +
geom_vline(xintercept = 7/12,
linetype = "dashed", linewidth = 1) +
ylim(0, 1) +
labs(
x = "Threshold",
y = "Win Chance",
title = "Player A Win Chance vs Threshold"
) +
theme_minimal()
1/4 + (7/8)*(7/12) - (3/4)*(7/12)^2
pacman::p_load(clogitR, dplyr, data.table, doFuture, future, doRNG, foreach, progressr, doParallel, nbpMatching, doParallel, ggplot2, geepack, glmmTMB, rstan) #doParallel
results = read.csv("C:/temp/clogitR_kap_test_from_scratch/100_1.csv")
results = read.csv("C:/temp/clogitR_kap_test_from_scratch/1000_1.csv")
sum = 1
for (i in 2:475) {
file_path <- paste0("C:/temp/clogitR_kap_test_from_scratch/10_", i, ".csv")
if (file.exists(file_path)) {
sum = sum +1
message("Reading file ", i)
temp <- read.csv(file_path)
results <- rbind(results, temp)
} else {
message("Skipping missing file ", i)
}
}
results$X = NULL
res_mod = results %>%
mutate(sq_err = (beta_hat_T - beta_T)^2, rej = pval < 0.05) %>%
group_by(beta_T, true_funtion, regress_on_X, n, inference, X_style) %>%
summarize(
num_na = sum(is.na(pval)),
num_real = sum(!is.na(pval)),
mse = mean(sq_err, na.rm = TRUE),
percent_reject = sum(rej, na.rm = TRUE) / (n() - num_na),
mean_beta_hat_T = mean(beta_hat_T, na.rm = TRUE),
mean_sq_beta_hat_T = mean(sqrt(ssq_beta_hat_T), trim = 0.001, na.rm = TRUE),
.groups = "drop")
write.csv(res_mod, file = "C:/temp/clogitR_kap_test_from_scratch/combined_160.csv", row.names = FALSE)
pacman::p_load(clogitR, dplyr, data.table, doFuture, future, doRNG, foreach, progressr, doParallel, nbpMatching, doParallel, ggplot2, geepack, glmmTMB, rstan) #doParallel
options(error = recover)
rm(list = ls())
############### parameters ###############
num_cores = availableCores() - 5
Nsim = 100
external_nsim = 100000
ns = c(100, 250, 500)
beta_Ts = c(0,1)
X_styles = c("correlated", "non-correlated")
true_funtions = c("linear", "non-linear")
regress_on_Xs = c("all", "one", "none")
pacman::p_load(clogitR, dplyr, data.table, doFuture, future, doRNG, foreach, progressr, doParallel, nbpMatching, doParallel, ggplot2, geepack, glmmTMB, rstan) #doParallel
options(error = recover)
rm(list = ls())
results = read.csv("C:/temp/clogitR_kap_test_from_scratch/100_1.csv")
sum = 1
for (i in 2:475) {
file_path <- paste0("C:/temp/clogitR_kap_test_from_scratch/100_", i, ".csv")
if (file.exists(file_path)) {
sum = sum +1
message("Reading file ", i)
temp <- read.csv(file_path)
results <- rbind(results, temp)
} else {
message("Skipping missing file ", i)
}
}
results$X = NULL
sum * 100
res_mod = results %>%
mutate(sq_err = (beta_hat_T - beta_T)^2, rej = pval < 0.05) %>%
group_by(beta_T, true_funtion, regress_on_X, n, inference, X_style) %>%
summarize(
num_na = sum(is.na(pval)),
num_real = sum(!is.na(pval)),
mse = mean(sq_err, na.rm = TRUE),
percent_reject = sum(rej, na.rm = TRUE) / (n() - num_na),
mean_beta_hat_T = mean(beta_hat_T, na.rm = TRUE),
mean_sq_beta_hat_T = mean(sqrt(ssq_beta_hat_T), trim = 0.001, na.rm = TRUE),
.groups = "drop")
write.csv(res_mod, file = "C:/temp/clogitR_kap_test_from_scratch/combined_46900.csv", row.names = FALSE)
??aov
?aov
data = MASS::Boston
summary(data)
data = Diamonds
summary(data)
data = MASS::Rubber
summary(data)
data = MASS::cats
summary(data)
require(data.table)
install.packages("tidycensus")
require(tidycensus)
census_api_key("7e44c115c0b1df243525bd7d71e72fc0ad49ff01")
census_data <- load_variables(2010, "sf1", cache=T)
View(census_data)
census_data <- load_variables(2010, "sf1", cache=T)
fwrite(census_data, "final_census_variables.csv")
vars <- c(totalhouse = 'H001001',
rental = 'H004004',
white = 'H006002',
Age = 'P013001',
Female = 'P018006')
require(data.table)
install.packages("tidycensus")
require(data.table)
install.packages("tidycensus")
require(tidycensus)
census_api_key("7e44c115c0b1df243525bd7d71e72fc0ad49ff01")
census_data <- load_variables(2010, "sf1", cache=T)
fwrite(census_data, "final_census_variables.csv")
vars <- c(totalhouse = 'H001001',
rental = 'H004004',
white = 'H006002',
Age = 'P013001',
Female = 'P018006')
tristate <- c("36", "34", "09")
tristate_df <- get_decennial(state = tristate,
geography = "county",
variables = vars,
geometry = T,
output = "wide",
year = 2010)
tristate_df
tristate_df$whitepct <- (tristate_df$white / tristate_df$totalhouse) *100
tristate_df$rentpct <- (tristate_df$rental / tristate_df$totalhouse) *100
tristate_df$fempct <- (tristate_df$Female / tristate_df$totalhouse) *100
tristate_df$medage <- median(tristate_df$Age)
nyccounty <- c("36005","36047","36061","36081","36085")
tristate_df$NYC <- ifelse('nyccounty', 1, 0)
head(tristate_df$NYC)
nyc_df <- get_decennial(state = "NY",
county = '36005, 36047, 36061,36081, 36085',
geography = county,
variables = vars,
geometry = T,
output = "wide",
year = 2010)
nyc_df$whitepct <- (nyc_df$white / nyc_df$totalhouse) *100
tristate_df
substr(tristate_df$GEOID,1,2)
table(substr(tristate_df$GEOID,1,2))
factor(substr(tristate_df$GEOID,1,2))
tristate_df$state <- factor(substr(tristate_df$GEOID,1,2))
tristate_df
ANOVA_rent <- aov(rentpct ~ state, data = tristate_df)
ANOVA_rent
summary(ANOVA_rent)
summary(lm(rentpct ~ state, data = tristate_df))
ANOVA_rent <- aov(rentpct ~ state, data = tristate_df)
ANOVA_rent
tristate_df$state <- factor(substr(tristate_df$GEOID,1,2))
ANOVA_rent <- aov(rentpct ~ state, data = tristate_df)
summary(ANOVA_rent)
tristate_df
summary(tristate_df$medage )
table(tristate_df$medage)
View(tristate_df)
ANOVA_age <- aov(rentpct ~ Age, data = tristate_df)
summary(ANOVA_age)
pacman::p_load(clogitR, dplyr, data.table, doFuture, future, doRNG, foreach, progressr, doParallel, nbpMatching, doParallel, ggplot2, geepack, glmmTMB, rstan) #doParallel
options(error = recover)
rm(list = ls())
results = read.csv("C:/temp/clogitR_kap_test_from_scratch/100_1.csv")
sum = 1
for (i in 2:475) {
file_path <- paste0("C:/temp/clogitR_kap_test_from_scratch/100_", i, ".csv")
if (file.exists(file_path)) {
sum = sum +1
message("Reading file ", i)
temp <- read.csv(file_path)
results <- rbind(results, temp)
} else {
message("Skipping missing file ", i)
}
}
results$X = NULL
res_mod = results %>%
mutate(sq_err = (beta_hat_T - beta_T)^2, rej = pval < 0.05) %>%
group_by(beta_T, true_funtion, regress_on_X, n, inference, X_style) %>%
summarize(
num_na = sum(is.na(pval)),
num_real = sum(!is.na(pval)),
mse = mean(sq_err, na.rm = TRUE),
percent_reject = sum(rej, na.rm = TRUE) / (n() - num_na),
mean_beta_hat_T = mean(beta_hat_T, na.rm = TRUE),
mean_sq_beta_hat_T = mean(sqrt(ssq_beta_hat_T), trim = 0.001, na.rm = TRUE),
.groups = "drop")
write.csv(res_mod, file = "C:/temp/clogitR_kap_test_from_scratch/combined_14000.csv", row.names = FALSE)
pacman::p_load(clogitR, dplyr, data.table, doFuture, future, doRNG, foreach, progressr, doParallel, nbpMatching, doParallel, ggplot2, geepack, glmmTMB, rstan) #doParallel
results = read.csv("C:/temp/clogitR_kap_test_from_scratch/100_1.csv")
sum = 1
for (i in 2:475) {
file_path <- paste0("C:/temp/clogitR_kap_test_from_scratch/100_", i, ".csv")
if (file.exists(file_path)) {
sum = sum +1
message("Reading file ", i)
temp <- read.csv(file_path)
results <- rbind(results, temp)
} else {
message("Skipping missing file ", i)
}
}
results$X = NULL
res_mod = results %>%
mutate(sq_err = (beta_hat_T - beta_T)^2, rej = pval < 0.05) %>%
group_by(beta_T, true_funtion, regress_on_X, n, inference, X_style) %>%
summarize(
num_na = sum(is.na(pval)),
num_real = sum(!is.na(pval)),
mse = mean(sq_err, na.rm = TRUE),
percent_reject = sum(rej, na.rm = TRUE) / (n() - num_na),
mean_beta_hat_T = mean(beta_hat_T, na.rm = TRUE),
mean_sq_beta_hat_T = mean(sqrt(ssq_beta_hat_T), trim = 0.001, na.rm = TRUE),
.groups = "drop")
write.csv(res_mod, file = "C:/temp/clogitR_kap_test_from_scratch/combined_4600.csv", row.names = FALSE)
pacman::p_load(clogitR, dplyr, data.table, doFuture, future, doRNG, foreach, progressr, doParallel, nbpMatching, doParallel, ggplot2, geepack, glmmTMB, rstan) #doParallel
options(error = recover)
rm(list = ls())
results = read.csv("C:/temp/clogitR_kap_test_from_scratch/100_1.csv")
sum = 1
for (i in 2:475) {
file_path <- paste0("C:/temp/clogitR_kap_test_from_scratch/100_", i, ".csv")
if (file.exists(file_path)) {
sum = sum +1
message("Reading file ", i)
temp <- read.csv(file_path)
results <- rbind(results, temp)
} else {
message("Skipping missing file ", i)
}
}
results$X = NULL
res_mod = results %>%
mutate(sq_err = (beta_hat_T - beta_T)^2, rej = pval < 0.05) %>%
group_by(beta_T, true_funtion, regress_on_X, n, inference, X_style) %>%
summarize(
num_na = sum(is.na(pval)),
num_real = sum(!is.na(pval)),
mse = mean(sq_err, na.rm = TRUE),
percent_reject = sum(rej, na.rm = TRUE) / (n() - num_na),
mean_beta_hat_T = mean(beta_hat_T, na.rm = TRUE),
mean_sq_beta_hat_T = mean(sqrt(ssq_beta_hat_T), trim = 0.001, na.rm = TRUE),
.groups = "drop")
write.csv(res_mod, file = "C:/temp/clogitR_kap_test_from_scratch/combined_5500.csv", row.names = FALSE)
Nsim = 100
external_nsim = 100000
ns = c(100, 250, 500)
beta_Ts = c(0,0.5)
X_styles = c("non-correlated") #"correlated",
true_funtions = c("linear", "non-linear")
regress_on_Xs = c("one", "two") #"all", "one", "none"
#Bayesian_prior_for_betaTs = c(TRUE, FALSE)
sm = rstan::stan_model("mvn_logistic.stan")
params = expand.grid(
nsim = 1:Nsim,
beta_T = beta_Ts,
n = ns,
X_style = X_styles
)
params = params %>%
arrange(nsim, beta_T, n, X_style)
pacman::p_load(clogitR, dplyr, data.table, doFuture, future, doRNG, foreach, progressr, doParallel, nbpMatching, doParallel, ggplot2, geepack, glmmTMB, rstan) #doParallel
options(error = recover)
rm(list = ls())
results = read.csv("C:/temp/clogitR_kap_test_from_scratch/100_1.csv")
sum = 1
for (i in 2:475) {
file_path <- paste0("C:/temp/clogitR_kap_test_from_scratch/100_", i, ".csv")
if (file.exists(file_path)) {
sum = sum +1
message("Reading file ", i)
temp <- read.csv(file_path)
results <- rbind(results, temp)
} else {
message("Skipping missing file ", i)
}
}
results$X = NULL
res_mod = results %>%
mutate(sq_err = (beta_hat_T - beta_T)^2, rej = pval < 0.05) %>%
group_by(beta_T, true_funtion, regress_on_X, n, inference, X_style) %>%
summarize(
num_na = sum(is.na(pval)),
num_real = sum(!is.na(pval)),
mse = mean(sq_err, na.rm = TRUE),
percent_reject = sum(rej, na.rm = TRUE) / (n() - num_na),
mean_beta_hat_T = mean(beta_hat_T, na.rm = TRUE),
mean_sq_beta_hat_T = mean(sqrt(ssq_beta_hat_T), trim = 0.001, na.rm = TRUE),
.groups = "drop")
res_mod
write.csv(res_mod, file = "C:/temp/clogitR_kap_test_from_scratch/combined_5700.csv", row.names = FALSE)
setwd("C:/Users/Jacob/clogitR_package_and_paper_repo/package_tests")
